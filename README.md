# GPT-5 MCP Server

A Model Context Protocol (MCP) server that brings OpenAI's GPT-5 capabilities to Claude Code. Features advanced reasoning, cost management, and conversation handling with automatic fallback to latest GPT-4 models.

## Why Use This?

- **Collaborative AI**: Combine Claude's capabilities with GPT-5's advanced reasoning
- **Cost Control**: Built-in spending limits, preflight estimates, per-conversation budgets
- **Efficient Context**: Context truncation + optional summarization to reduce tokens
- **Conversation Management**: Maintain multi-turn conversations with GPT-5
- **Automatic Fallback**: Seamlessly falls back to GPT-4 family with retries/backoff
- **File Support**: Process PDFs, images, and documents via Claude Code's @ syntax
- **Observability**: JSON outputs, usage CSV, optional webhook alerts
- **Easy Setup**: Interactive wizard handles all configuration and validation

## Prerequisites

- **OpenAI API Key** with sufficient credits ([get one here](https://platform.openai.com/api-keys))
- **Verified OpenAI Organization** - Required for GPT-5 API access ([verification guide](https://help.openai.com/en/articles/10910291-api-organization-verification))
- **Node.js 18+** and **npm**
- **Claude Code CLI** or **Claude Desktop**

## ðŸš€ Quick Setup (Recommended)

**One-command setup with interactive wizard (3 minutes):**

```bash
git clone https://github.com/andreahaku/gpt5_mcp
cd gpt5-mcp
npm install
npm run build
npm run setup
```

The setup wizard will:
- âœ… **Validate your OpenAI API key** and test model access
- âœ… **Guide fallback model selection** from 6 latest models
- âœ… **Configure cost limits** with flexible USD amounts (minimum $1)
- âœ… **Set AI behavior preferences** (reasoning effort, verbosity)
- âœ… **Create your .env file** automatically with validation
- âœ… **Generate Claude Desktop JSON** config for copy/paste
- âœ… **Generate Claude Code CLI commands** with absolute paths
- âœ… **Provide complete setup instructions** and troubleshooting

**After the wizard:**
1. Copy the Claude Desktop JSON to your config file (path shown by wizard)
2. OR run the Claude Code CLI command (generated by wizard)
3. Restart Claude Desktop or verify with `claude mcp list`

**That's it!** Your GPT-5 MCP server will be ready to use.

## Available Fallback Models

When GPT-5 is unavailable, the server automatically uses your chosen fallback:

- **gpt-4.1** - Latest GPT-4 iteration with enhanced capabilities
- **o3** - Advanced reasoning model for complex tasks
- **o3-deep-research** - Specialized for in-depth analysis and research
- **o4-mini** - Compact, efficient model for quick responses
- **o3-mini** - Lightweight reasoning model with balanced performance
- **gpt-4o** - Multimodal GPT-4 with vision capabilities

## Configuration

### Environment Variables

Create a `.env` file with your OpenAI API key and optional tuning:

```env
# Required
OPENAI_API_KEY=sk-your-api-key-here

# Cost limits (defaults shown)
DAILY_COST_LIMIT=10.00
TASK_COST_LIMIT=2.00

# Reasoning defaults
DEFAULT_TEMPERATURE=0.7
DEFAULT_REASONING_EFFORT=high

# Conversation controls
MAX_CONVERSATION_CONTEXT=10       # messages kept per call
MAX_INSTRUCTION_TOKENS=1500       # truncate very long instructions
CONVERSATION_HARD_CAP_MULTIPLIER=10

# Resource handling
RESOURCE_MAX_TOKENS=1500          # per-resource token budget
RESOURCE_MAX_COUNT=5              # max resources included per call

# OpenAI model and client behavior
OPENAI_RESPONSES_MODEL=gpt-5
OPENAI_FALLBACK_MODELS=gpt-4o,gpt-4o-mini,gpt-4-turbo-preview,gpt-4-turbo,gpt-4,gpt-3.5-turbo
OPENAI_RETRY_COUNT=3
OPENAI_RETRY_BASE_DELAY_MS=300
OPENAI_TIMEOUT_MS=30000

# Alerts
ALERT_WEBHOOK_URL=                # optional URL to POST alerts (JSON)
```

## Available Tools

### 1. `consult_gpt5`
Get GPT-5 assistance with advanced reasoning and file support.

**Key parameters:**
- `prompt` (required): Your question or task
- `reasoning_effort`: minimal, low, medium, or high (default: high)
- `max_tokens`: Maximum response length (default: 20000, down-capped by budget)
- `task_budget`: USD limit for this specific task
- `confirm_spending`: Proceed even if over daily limit
- `stream`: enable streaming (server aggregates; client receives final text)

### 2. `start_conversation`
Begin a multi-turn conversation with GPT-5.

**Parameters:**
- `topic` (required): What the conversation is about
- `instructions`: Optional system-level guidance
- `budget_limit`: Optional per-conversation budget (USD)

### 3. `continue_conversation`
Continue an existing conversation thread.

**Parameters:**
- `conversation_id` (required): ID from start_conversation
- `message` (required): Your next message
- `max_tokens`: optional cap for this single turn (down-capped by budget)
- `budget_limit`: set/override per-conversation budget
- `confirm_spending`: proceed when near/over budget
- `stream`: enable streaming (server aggregates; client receives final text)

### 4. `set_conversation_options`
Update per-conversation options without sending a message.

**Parameters:**
- `conversation_id` (required)
- `budget_limit`: set/override per-conversation budget
- `context_limit`: override messages kept in context per call

### 5. `get_cost_report`
View usage statistics and costs.

**Parameters:**
- `period`: current_task, today, week, or month

### 6. `set_cost_limits`
Configure spending limits.

**Parameters:**
- `daily_limit`: Maximum daily spending in USD
- `task_limit`: Maximum per-task spending in USD

## Usage Examples

### Basic Usage
```
"Use GPT-5 to help me design a REST API for user authentication"
"Ask GPT-5 to review this code for security issues"
"Get GPT-5's help optimizing this database query"
```

### File Analysis
```
"@config.json Ask GPT-5 to review this configuration for security issues"
"@screenshot.png What UI improvements would GPT-5 suggest for this design?"
"@document.pdf Summarize the key points from this report using GPT-5"
```

### Multi-turn Conversations
```
"Start a GPT-5 conversation about optimizing database queries"
"Continue the conversation: What about indexing strategies?"
"Continue: How does this apply to time-series data?"
```

### Cost Management
```
"Get cost report for today"
"Show my current spending limits"  
"Get usage breakdown for this week"
```

## ðŸ”§ Advanced Setup (Manual)

If you prefer manual configuration or need custom settings:

### Environment Variables

The setup wizard creates a `.env` file with these variables:

```env
# Required
OPENAI_API_KEY=sk-your-api-key-here

# Cost Management (USD)
DAILY_COST_LIMIT=10.00                    # Daily spending limit
TASK_COST_LIMIT=5.00                      # Per-task spending limit

# AI Behavior Settings  
DEFAULT_REASONING_EFFORT=high             # minimal, low, medium, high
DEFAULT_VERBOSITY=medium                  # low, medium, high

# Fallback Model Configuration
FALLBACK_MODEL=gpt-4o                     # Model to use when GPT-5 unavailable

# Additional Settings
DEFAULT_TEMPERATURE=0.7                   # Creativity/randomness (0.0-2.0)
LOG_LEVEL=info                           # debug, info, warn, error
```

### Manual Claude Code CLI Setup

```bash
# Option 1: Using .env file (recommended)
claude mcp add gpt5 --env-file "$(pwd)/.env" -- node "$(pwd)/dist/index.js"

# Option 2: Individual environment variables
claude mcp add gpt5 \
  --env OPENAI_API_KEY=sk-your-key \
  --env DAILY_COST_LIMIT=10.00 \
  --env TASK_COST_LIMIT=5.00 \
  --env FALLBACK_MODEL=gpt-4o \
  -- node "$(pwd)/dist/index.js"
```

### Manual Claude Desktop Setup

Edit your Claude Desktop config file:

**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`
**Windows**: `%APPDATA%\Claude\claude_desktop_config.json`  
**Linux**: `~/.config/Claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "gpt5": {
      "command": "node",
      "args": ["/absolute/path/to/gpt5-mcp/dist/index.js"],
      "env": {
        "OPENAI_API_KEY": "sk-your-api-key-here",
        "DAILY_COST_LIMIT": "10.00",
        "TASK_COST_LIMIT": "5.00",
        "FALLBACK_MODEL": "gpt-4o"
      }
    }
  }
}
```

Then restart Claude Desktop completely.

## Development Commands

```bash
# Setup and Configuration
npm run setup                # Interactive setup wizard
npm install                  # Install dependencies  
npm run build               # Compile TypeScript

# Development
npm run dev                 # Development mode with hot reload
npm test                    # Run test suite
npm run test:watch          # Watch mode for testing
npm run test:coverage       # Generate coverage report

# Docker (Optional)
npm run docker:build        # Build Docker image
npm run docker:run          # Run in Docker container

# Utilities
npm run clean              # Remove build artifacts
npm start                  # Interactive launcher menu
```

## Troubleshooting

### Setup Wizard Issues

**Wizard fails to start:**
- Ensure Node.js 18+ is installed: `node --version`
- Make sure you're in the project directory
- Try: `npm install && npm run build && npm run setup`

**API key validation fails:**
- Verify your key starts with `sk-` and is not expired
- Check your OpenAI billing dashboard has sufficient credits
- Ensure your organization is verified for GPT-5 access

**Model access validation fails:**
- Some models require special access or beta participation
- Try selecting a different fallback model (gpt-4o is most reliable)
- Check your organization's model access in OpenAI dashboard

### Claude Integration Issues

**Server not appearing in Claude Desktop:**
- Verify config file path is correct for your OS
- Use absolute paths, not relative paths  
- Completely quit and restart Claude Desktop (not just reload)
- Check that `dist/index.js` exists (run `npm run build`)

**Claude Code CLI issues:**
- Verify server was added: `claude mcp list`
- Check server status: `/mcp` (inside Claude Code)
- Remove and re-add if needed: `claude mcp remove gpt5`
- Ensure absolute paths in commands

**MCP Server errors:**
- Check `.env` file exists and has valid API key
- Verify Node.js permissions and file access
- Look for error logs in terminal output
- Test direct server start: `node dist/index.js`

### API and Billing Issues

**Cost Limits:**
- Configure limits in `.env` file
- Use `get_cost_report` tool to monitor usage
- Daily default: $10, Task default: $2
- For more control, set per-conversation budgets via `start_conversation` or `set_conversation_options`.
- The server preflights costs and may ask for `confirm_spending=true` to proceed when budgets are tight.

**"Insufficient credits" errors:**
- Check your OpenAI billing dashboard
- Add payment method or increase credit balance
- Monitor usage with `get_cost_report` tool

**Model access denied:**
- Verify organization verification status
- Some models require waitlist access
- Try different fallback models
- Check model availability: https://platform.openai.com/docs/models

### Getting Help

- **OpenAI API Status**: https://status.openai.com/
- **Claude Code Documentation**: https://docs.anthropic.com/en/docs/claude-code
- **Organization Verification**: https://help.openai.com/en/articles/10910291-api-organization-verification
- **MCP Specification**: https://spec.modelcontextprotocol.io/

## Project Structure

```
gpt5-mcp/
â”œâ”€â”€ src/              # TypeScript source
â”‚   â”œâ”€â”€ setup/        # Setup wizard modules  
â”‚   â”œâ”€â”€ index.ts      # Main MCP server
â”‚   â”œâ”€â”€ openai-client.ts   # OpenAI API wrapper
â”‚   â”œâ”€â”€ cost-manager.ts    # Usage tracking
â”‚   â””â”€â”€ conversation.ts    # Multi-turn conversations
â”œâ”€â”€ dist/             # Compiled JavaScript
â”œâ”€â”€ data/             # Persistent usage data
â”œâ”€â”€ tests/            # Jest unit tests
â”œâ”€â”€ docs/             # Additional documentation
â”œâ”€â”€ setup.js          # Interactive setup wizard
â””â”€â”€ .env              # Configuration (created by wizard)
```

## License

MIT License - see LICENSE file for details.

## Support

For issues or questions, please open an issue on [GitHub](https://github.com/andreahaku/gpt5_mcp).

---
- `task_limit`: Maximum per-task spending in USD

### 7. `get_conversation_metadata`
Return conversation object in JSON (metadata + messages).

### 8. `summarize_conversation`
Compress older messages into a concise summary to reduce future token usage.

**Parameters:**
- `conversation_id` (required)
- `keep_last_n` (default 5): number of recent messages to keep verbatim
- `max_tokens` (default 2000): budget for generating the summary

**Note**: This server uses OpenAI's GPT-5 Responses API when available and automatically falls back to the latest GPT-4 models with optimized parameters if needed.